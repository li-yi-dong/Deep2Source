# Megatron-LM
## GitHub
https://github.com/NVIDIA/Megatron-LM
## Paper
* [Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism](https://arxiv.org/abs/1909.08053)
* [Reducing Activation Recomputation in Large Transformer Models](https://arxiv.org/abs/2205.05198)
* [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473)
* [Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model](https://arxiv.org/abs/2201.11990)